{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class double_conv2d_bn(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=3,strides=1,padding=1):\n",
    "        super(double_conv2d_bn,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,\n",
    "                               kernel_size=kernel_size,\n",
    "                              stride = strides,padding=padding,bias=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels,out_channels,\n",
    "                              kernel_size = kernel_size,\n",
    "                              stride = strides,padding=padding,bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        return out\n",
    "    \n",
    "class deconv2d_bn(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=2,strides=2):\n",
    "        super(deconv2d_bn,self).__init__()\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels,out_channels,\n",
    "                                        kernel_size = kernel_size,\n",
    "                                       stride = strides,bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        return out\n",
    "    \n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet,self).__init__()\n",
    "        self.layer1_conv = double_conv2d_bn(1,8)\n",
    "        self.layer2_conv = double_conv2d_bn(8,16)\n",
    "        self.layer3_conv = double_conv2d_bn(16,32)\n",
    "        self.layer4_conv = double_conv2d_bn(32,64)\n",
    "        self.layer5_conv = double_conv2d_bn(64,128)\n",
    "        self.layer6_conv = double_conv2d_bn(128,64)\n",
    "        self.layer7_conv = double_conv2d_bn(64,32)\n",
    "        self.layer8_conv = double_conv2d_bn(32,16)\n",
    "        self.layer9_conv = double_conv2d_bn(16,8)\n",
    "        self.layer10_conv = nn.Conv2d(8,1,kernel_size=3,\n",
    "                                     stride=1,padding=1,bias=True)\n",
    "        \n",
    "        self.deconv1 = deconv2d_bn(128,64)\n",
    "        self.deconv2 = deconv2d_bn(64,32)\n",
    "        self.deconv3 = deconv2d_bn(32,16)\n",
    "        self.deconv4 = deconv2d_bn(16,8)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv1 = self.layer1_conv(x)\n",
    "        pool1 = F.max_pool2d(conv1,2)\n",
    "        \n",
    "        conv2 = self.layer2_conv(pool1)\n",
    "        pool2 = F.max_pool2d(conv2,2)\n",
    "        \n",
    "        conv3 = self.layer3_conv(pool2)\n",
    "        pool3 = F.max_pool2d(conv3,2)\n",
    "        \n",
    "        conv4 = self.layer4_conv(pool3)\n",
    "        pool4 = F.max_pool2d(conv4,2)\n",
    "        \n",
    "        conv5 = self.layer5_conv(pool4)\n",
    "        \n",
    "        convt1 = self.deconv1(conv5)\n",
    "        concat1 = torch.cat([convt1,conv4],dim=1)\n",
    "        conv6 = self.layer6_conv(concat1)\n",
    "        \n",
    "        convt2 = self.deconv2(conv6)\n",
    "        concat2 = torch.cat([convt2,conv3],dim=1)\n",
    "        conv7 = self.layer7_conv(concat2)\n",
    "        \n",
    "        convt3 = self.deconv3(conv7)\n",
    "        concat3 = torch.cat([convt3,conv2],dim=1)\n",
    "        conv8 = self.layer8_conv(concat3)\n",
    "        \n",
    "        convt4 = self.deconv4(conv8)\n",
    "        concat4 = torch.cat([convt4,conv1],dim=1)\n",
    "        conv9 = self.layer9_conv(concat4)\n",
    "        outp = self.layer10_conv(conv9)\n",
    "        outp = self.sigmoid(outp)\n",
    "        return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "model = Unet()\n",
    "inp = torch.rand(10,1,224,224)\n",
    "outp = model(inp)\n",
    "print(outp.shape)\n",
    "# ==> torch.Size([10, 1, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch 常用函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.维度变换\n",
    "`permute`(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024, 16, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "x = torch.randn(8, 1024, 16, 512) \n",
    "x.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1024, 512, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(0, 1, 3, 2).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`transpose`与`permute`的异同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 16, 8, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,3).transpose(2,1).transpose(3,2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`permute`函数与`contiguous`、`view`函数之关联\n",
    "\n",
    "`contiguous`：`view`只能作用在`contiguous`的`variable`上，如果在`view`之前调用了`transpose`、`permute`等，就需要调用`contiguous()`来返回一个`contiguous` copy；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(10, 10) \n",
    "a.is_contiguous()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1).is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1).contiguous().is_contiguous() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n",
      "torch.Size([3, 1, 2])\n",
      "torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=np.array([[[1,2,3],[4,5,6]]])\n",
    "unpermuted=torch.tensor(a)\n",
    "print(unpermuted.size())              #  ——>  torch.Size([1, 2, 3])\n",
    "\n",
    "permuted=unpermuted.permute(2,0,1)\n",
    "print(permuted.size())                #  ——>  torch.Size([3, 1, 2])\n",
    "\n",
    "view_test = unpermuted.view(1,3,2)\n",
    "print(view_test.size())               #  ——>  torch.Size([1, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.Tensor([1,2,3,4])\n",
    "b = torch.randn(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1117, -0.4966,  0.1631, -0.8817,  0.0539,  0.6684],\n",
      "         [-0.0597, -0.4675, -0.2153,  0.8840, -0.7584, -0.3689],\n",
      "         [-0.3424, -1.4020,  0.3206, -1.0219,  0.7988, -0.0923],\n",
      "         [-0.7049, -1.6024,  0.2891,  0.4899, -0.3853, -0.7120]],\n",
      "\n",
      "        [[-0.1706, -1.4594,  0.2207,  0.2463, -1.3248,  0.6970],\n",
      "         [-0.6631,  1.2158, -1.4949,  0.8810, -1.1786, -0.9340],\n",
      "         [-0.5675, -0.2772, -2.1834,  0.3668,  0.9380,  0.0078],\n",
      "         [-0.3139, -1.1567,  1.8409, -1.0174,  1.2192,  0.1601]]]) \n",
      " tensor([[[ 1.5985, -0.0469, -1.5270, -2.0143, -1.5173,  0.3877],\n",
      "         [-1.1849,  0.6897,  1.3232,  1.8169,  0.6808,  0.7244],\n",
      "         [ 0.0323, -1.6593, -1.8773,  0.7372,  0.9257,  0.9247],\n",
      "         [ 0.1825, -0.0737,  0.3147, -1.0369,  0.2100,  0.6144]],\n",
      "\n",
      "        [[ 0.0628, -0.3297, -1.7970,  0.8728,  0.7670, -0.1138],\n",
      "         [-0.9428,  0.7540,  0.1407, -0.6937, -0.6159, -0.7295],\n",
      "         [ 0.4308,  0.2862, -0.2481,  0.2040,  0.8519, -1.4102],\n",
      "         [-0.1071, -0.8018,  0.2771,  2.5599, -1.6952,  0.1885]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "x = torch.randn(2, 4, 6) \n",
    "y = torch.randn(2, 4, 6)\n",
    "print(x, '\\n',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x*y).shape # 对应元素相乘 \n",
    "torch.mul(x,y).shape #等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4.],\n",
       "        [4., 4.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3,4)\n",
    "b = torch.ones(4,2)\n",
    "torch.mm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x2 and 3x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26386/84847464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x2 and 3x4)"
     ]
    }
   ],
   "source": [
    "torch.mm(b, a) # 不能换位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.matmul是torch.mm的broadcast版本."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5,2,4)*2\n",
    "b = torch.ones(5,4,2)\n",
    "print (torch.matmul(a, b).shape)\n",
    "# torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4696, -1.3284,  1.9946],\n",
      "        [-0.8209,  1.0061, -1.0664]])\n",
      "tensor([[0.3634, 0.0221, 0.6144],\n",
      "        [0.1250, 0.7772, 0.0978]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9081, 0.0883, 0.9553],\n",
       "        [0.0919, 0.9117, 0.0447]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "print(input)\n",
    "output = m(input)\n",
    "print (output)\n",
    "F.softmax(input, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 6])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5,4,4)\n",
    "b = torch.ones(5,4,2)*2\n",
    "torch.cat((b,a), 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024, 6])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(4,64,6)\n",
    "b = torch.randn(4,64,16)\n",
    "raw_size = b.size()\n",
    "idx = b.reshape(raw_size[0], -1)\n",
    "idx[..., None].expand(-1, -1, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1., 1.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4., 4., 4., 4., 4., 4.],\n",
       "        [4., 4., 4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.ones(2,4,6)\n",
    "print(b)\n",
    "torch.einsum('bmf->bf', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1117, -0.4966,  0.1631, -0.8817,  0.0539,  0.6684],\n",
       "         [-0.0597, -0.4675, -0.2153,  0.8840, -0.7584, -0.3689],\n",
       "         [-0.3424, -1.4020,  0.3206, -1.0219,  0.7988, -0.0923],\n",
       "         [-0.7049, -1.6024,  0.2891,  0.4899, -0.3853, -0.7120]],\n",
       "\n",
       "        [[-0.1706, -1.4594,  0.2207,  0.2463, -1.3248,  0.6970],\n",
       "         [-0.6631,  1.2158, -1.4949,  0.8810, -1.1786, -0.9340],\n",
       "         [-0.5675, -0.2772, -2.1834,  0.3668,  0.9380,  0.0078],\n",
       "         [-0.3139, -1.1567,  1.8409, -1.0174,  1.2192,  0.1601]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "b = torch.randn(2,4,6)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[-0.0597, -0.4675,  0.3206,  0.8840,  0.7988,  0.6684],\n",
       "        [-0.1706,  1.2158,  1.8409,  0.8810,  1.2192,  0.6970]]),\n",
       "indices=tensor([[1, 1, 2, 1, 2, 0],\n",
       "        [0, 1, 3, 1, 3, 0]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(b,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1466, 0.0998, 0.1930, 0.0679, 0.1730, 0.3198],\n",
       "         [0.1582, 0.1052, 0.1354, 0.4064, 0.0787, 0.1161],\n",
       "         [0.1218, 0.0422, 0.2364, 0.0617, 0.3814, 0.1564],\n",
       "         [0.1022, 0.0417, 0.2762, 0.3376, 0.1407, 0.1015]],\n",
       "\n",
       "        [[0.1435, 0.0396, 0.2122, 0.2177, 0.0453, 0.3417],\n",
       "         [0.0713, 0.4667, 0.0310, 0.3339, 0.0426, 0.0544],\n",
       "         [0.0880, 0.1176, 0.0175, 0.2240, 0.3965, 0.1564],\n",
       "         [0.0596, 0.0256, 0.5137, 0.0295, 0.2759, 0.0957]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(b, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcfe3673355d51ce39fcd143ee448a2c2a62ce3d4935bb32670db7a58e7efd78"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
